



---
title: "Practica02"
author: "Christian Meza, Carlos Alama y Rony Orocollo"
date: "2024-05-17"
output: html_document
---

# Actividad Evaluable 2

## 1. Datos Elegantes + Análisis de Datos con Web Scrapping

### Pregunta 1:

Queremos programar un programa de tipo web scrapping con el que podamos obtener una página web, mediante su URL, y poder analizar su contenido HTML con tal de extraer datos e información específica.

#### 1.1. Descargar la página web de la URL indicada, y almacenarlo en un formato de "R" apto para ser tratado.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Instalaciòn de las librerìas
```{r carga_librerias, warning=FALSE, message=FALSE}
#install.packages("httr")
#install.packages("XML")
library(httr)
library(XML)
```

URL de la página web a descargar

```{r get_pagina}
url <- "https://www.mediawiki.org/wiki/MediaWiki.com"
respuesta <- GET(url)

# Obtener el contenido de la respuesta como texto
contenido_html <- content(respuesta, as = "text", encoding = "UTF-8")
contenido_xml <- htmlTreeParse(contenido_html, useInternalNodes = TRUE)
```

##### 1.2. Analizar el contenido de la web, buscando el título de la página (que en HTML se etiqueta como “title”).
```{r get_titulo}
# Extraer el título de la página
titulo <- xpathSApply(contenido_xml, "//title", xmlValue)
```

El titulo es: `r titulo`.

##### 1.3. Analizar el contenido de la web, buscando todos los enlaces (que en HTML se etiquetan como “a”), buscando el texto del enlace, así como la URL.

```{r mostrar_enlaces}

# Extraer URL de los enlace <a>
urls_enlaces <- xpathSApply(contenido_xml, "//a", xmlGetAttr, "href")

# Extraer todos los textos de los enlace <href>
texto_enlaces <- xpathSApply(contenido_xml, "//a", xmlValue)

tabla_datos <- data.frame("Enlace" = urls_enlaces,"texto" = texto_enlaces,stringsAsFactors = F)

tabla_datos

```

##### 1.4. Generar una tabla con cada enlace encontrado, indicando el texto que acompaña el enlace, y el número de veces que aparece un enlace con ese mismo objetivo.

```{r mostrar_tabla}

# Contar la frecuencia de cada enlace
  tabla_datos$Frecuencia <- table(tabla_datos$Enlace)[as.character(tabla_datos$Enlace)]

tabla_datos
``` 


##### 1.5. Para cada enlace, seguirlo e indicar si está activo (podemos usar el código de status HTTP al hacer una petición a esa URL).
```{r mostrar_url_activo}

##convertir url de relativas a absolutas  
convertir_url <- function(url){
  if(grepl("^/|#", url)) {
    url <-paste0("https://www.mediawiki.org/", url)
  } 
    return(url)
}

## Función para verificar el estado de la URL
verificar_estado <- function(url){
    tryCatch({
      respuesta <- HEAD(url)
      if (status_code(respuesta) == 200) {
        Sys.sleep(2)
        return("200")
      } else {
        return("nulo")
      }
    }, error = function(e) {
      return("nulo")
    })
  }  
tabla_datos$Estado <- lapply(tabla_datos$Enlace, verificar_estado)

tabla_datos
```









Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.